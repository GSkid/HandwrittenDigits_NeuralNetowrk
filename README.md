# HandwrittenDigit_NeuralNetwork
# Author: Grant Skidmore

This repository uses the MNIST dataset of handwritten digits (http://yann.lecun.com/exdb/mnist/) to create a neural network that can classify images of handwritten digits as a number between 0 and 9. This project serves as my introduction to pyTorch, the Cuda core based python library that allows machine learning processes to exploit inherent advantages of GPUs to speed-up training and testing time. The pyTorch library also provides automatic backpropogation calcuations for multiple tensors, which are the fundamental objects for building artifically intelligent models. To learn more about pyTorch, visit this page: https://pytorch.org/. I also used this youtube series (https://www.youtube.com/watch?v=aircAruvnKk) and this blog post (https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627) to learn about the basic program flow for pyTorch and neural network computing.

The idea with this project is to classify an image into a 0 - 9 digit based on the greyscale values of each pixel in the image. The images provided from the MNIST database are all 28 x 28 pixels, resulting in a total of 784 pixels per image. The code creates a neural network using pyTorch Tensors to analyze each image and based on the pixel inputs and configurable weight matrices, maps each image to a digit. The network does not return a strictly digital output providing its answer, instead it maps the image to a probability for each 0 - 9 digit, the highest probability for each image is then returned as the network's 'guess'. However, this is not always right, especially when initially training the network. To make the network better, it learns after each run through of the images by calculating the gradient descent of the weight matrices. It then takes this gradient and incrementally adds it to the weight matrix so that the network's guesses slowly get closer to correct classification of each image. 

At some point, the network effectively classifies most handwritten digits, spitting out a number when provided with a 28 x 28 pixel image. You could say that the network learned what the numbers looked like by picking up on patterns, but I don't think this is the case. I believe that in order to consider the network to have learned what the numbers look like, it would need to be able to draw each digit based on the same model. However, this is already disproved by providing the network with a 28 x 28 pixel image that is not a handwritten digit. Instead of returning a low probability for all digits, it instead confidently returns one of the digits as if the image where a handwritten number. This means that the network is not necessarily looking for specific patterns that resemble numbers, instead it is more likely just blindly performing analyses on the pixels looking at small sub-set patterns in the image and saying, 'Hey that small pattern looks kind of like a 5, close enough'. Regardless, it is able to identify handwritten numbers well which I think is good enough for this purpose. 
